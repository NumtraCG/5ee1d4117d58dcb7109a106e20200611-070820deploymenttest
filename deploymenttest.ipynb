{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR deploymenttest PIPELINE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONNECTOR FUNCTIONS TO READ DATA FROM DATABRICKS FILESYSTEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class DBFSConnector:\n",
    "\n",
    "    def fetch(inStages, inStagesData, stageId, spark, config):\n",
    "        df = spark.read.\\\n",
    "            options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                    inferschema='true',\n",
    "                    delimiter=eval(config)[\"delimiter\"])\\\n",
    "            .csv(eval(config)['url'])\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(inStages, inStagesData, stageId, spark, config):\n",
    "        return inStagesData.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                                        delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMATIONS FUNCTIONS THAT WILL BE APPLIED ON DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import mean, stddev, min, max, col\n",
    "\n",
    "\n",
    "class CleanseData:\n",
    "    # def __init__(self,df):\n",
    "    #     #print()\n",
    "\n",
    "    def replaceByMean(self, feature, df, mean_=-1):\n",
    "\n",
    "        meanValue = df.select(mean(col(feature.name)).alias(\n",
    "            'mean')).collect()[0][\"mean\"]\n",
    "        df.fillna(meanValue, subset=[feature.name])\n",
    "        df.withColumn(feature.name, when(col(feature.name) == \" \",\n",
    "                                         meanValue).otherwise(col(feature.name).cast(\"Integer\")))\n",
    "        return df\n",
    "\n",
    "    def replaceByMax(self, feature, df, max_=-1):\n",
    "        maxValue = df.select(max(col(feature.name)).alias('max')).collect()[\n",
    "            0][\"max\"]\n",
    "        df.fillna(maxValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", maxValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByMin(self, feature, df, min_=-1):\n",
    "        minValue = df.select(min(col(feature.name)).alias('min')).collect()[\n",
    "            0][\"min\"]\n",
    "        df.fillna(minValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", minValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByStandardDeviation(self, feature, df, stddev_=-1):\n",
    "        stddevValue = df.select(stddev(col(feature.name)).alias(\n",
    "            'stddev')).collect()[0][\"stddev\"]\n",
    "        df.fillna(stddevValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", stddevValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceDateRandomly(self, feature, df):\n",
    "        fillValue = df.where(col(feature.name).isNotNull()\n",
    "                             ).head(1)[0][feature.name]\n",
    "        df.fillna(str(fillValue), subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", fillValue).otherwise(col(feature.name)))\n",
    "        # print(\"CleanseData:replaceDateRandomly Schema : \", df.#printSchema())\n",
    "        return df\n",
    "\n",
    "    def replaceNullValues(self, fList, df):\n",
    "        featuresList = df.schema.fields\n",
    "        for featureObj in fList:\n",
    "            for feat in featuresList:\n",
    "                if featureObj[\"feature\"] in feat.name:\n",
    "                    featureName = feat\n",
    "                    if \"mean\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMean(featureName, df)\n",
    "                    elif \"max\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMax(featureName, df)\n",
    "                    elif \"min\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMin(featureName, df)\n",
    "                    elif \"stddev\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByStandardDeviation(featureName, df)\n",
    "                    elif \"random\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceDateRandomly(featureName, df)\n",
    "        return df\n",
    "\n",
    "\n",
    "def StringIndexerTransform(df, params):\n",
    "    dfReturn = df\n",
    "    feature = params[\"feature\"]\n",
    "\n",
    "    dfReturn = dfReturn.fillna({feature: ''})\n",
    "    outcol = feature + \"_transform\"\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=feature, outputCol=outcol, handleInvalid=\"skip\")\n",
    "    indexed = indexer.fit(dfReturn).transform(dfReturn)\n",
    "    indexed = indexed.drop(feature).withColumnRenamed(outcol, feature)\n",
    "    dfReturn = indexed\n",
    "    distinct_values_list = dfReturn.select(\n",
    "        feature).distinct().rdd.map(lambda r: r[0]).collect()\n",
    "    len_distinct_values_list = len(distinct_values_list)\n",
    "    if len_distinct_values_list <= 4:\n",
    "        changed_type_df = dfReturn.withColumn(\n",
    "            feature, dfReturn[feature].cast(IntegerType()))\n",
    "        return changed_type_df\n",
    "    # changed_type_df.show(3)\n",
    "    return dfReturn\n",
    "\n",
    "\n",
    "class TransformationMain:\n",
    "    # TODO: change df argument in run with following\n",
    "    def run(transformationDF, config):\n",
    "        configObj = json.loads(config)\n",
    "        featureData = configObj[\"FE\"]\n",
    "        transformationDF = CleanseData().replaceNullValues(featureData, transformationDF)\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'City'}, 'feature': 'City', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "                                                  'count': '351', 'mean': '', 'stddev': '', 'min': 'ARVADA', 'max': 'WHEAT RIDGE', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Product_Category'}, 'feature': 'Product_Category', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'Furniture', 'max': 'Technology', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Product_Sub-Category'}, 'feature': 'Product_Sub-Category', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'Appliances', 'max': 'Telephones and Communication', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Customer Segment'}, 'feature': 'Customer Segment', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'Consumer', 'max': 'Small Business', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'First Name'}, 'feature': 'First Name', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'ALXXX', 'max': 'WX', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Last Name'}, 'feature': 'Last Name', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'ABXXXXX', 'max': 'ZAXXXXXX', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Address'}, 'feature': 'Address', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': '1003 WESTVIEW CT', 'max': '9826 NEWLAND CT', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'State'}, 'feature': 'State', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'CO', 'max': 'CO', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'MOSAIC HOUSEHOLD'}, 'feature': 'MOSAIC HOUSEHOLD', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'A01', 'max': 'U00', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'MOSAIC DESCRIPTION'}, 'feature': 'MOSAIC DESCRIPTION', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'Autumn Years', 'max': 'Young City Solos', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': {'feature_label': 'Channel'}, 'feature': 'Channel', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '351', 'mean': '', 'stddev': '', 'min': 'Catalog', 'max': 'eCommerce', 'missing': '0'}, 'transformation': 'String Indexer'})\n",
    "        display(transformationDF.limit(2).toPandas())\n",
    "        return transformationDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTOML FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyspark\n",
    "\n",
    "\n",
    "def functionClassification(sparkDF, listOfFeatures, label):\n",
    "    sparkDF.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = sparkDF.toPandas()\n",
    "    df.columns.intersection(listOfFeatures)\n",
    "    X = df.drop(label, axis=1).values\n",
    "    y = df[label].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.1)\n",
    "    tpotModel = TPOTClassifier(verbosity=3, n_jobs=-1, generations=10, max_time_mins=5,\n",
    "                               population_size=15)\n",
    "    tpotModel.fit(X_train, y_train)\n",
    "    display(\" Accuracy of Model : %s\" % tpotModel.score(X_test, y_test))\n",
    "    data = {'model': tpotModel,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'label': label,\n",
    "            'columnNames': sparkDF.columns}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READING DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "try: \n",
    "\tdeploymenttestdbfs = DBFSConnector.fetch([], {}, \"5ee1d4117d58dcb7109a106f\", spark, \"{'url': '/Demo/CustomerAcquisitionTrain.csv', 'file_type': 'Delimeted', 'delimiter': ',', 'is_header': 'Use Header Line'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMING DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "\tdeploymenttestautofe = TransformationMain.run(deploymenttestdbfs,json.dumps( {\"FE\": [{\"transformationsData\": {\"feature_label\": \"City\"}, \"feature\": \"City\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"ARVADA\", \"max\": \"WHEAT RIDGE\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"Product_Category\"}, \"feature\": \"Product_Category\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"Furniture\", \"max\": \"Technology\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"Product_Sub-Category\"}, \"feature\": \"Product_Sub-Category\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"Appliances\", \"max\": \"Telephones and Communication\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {}, \"feature\": \"Count\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"1.09\", \"stddev\": \"0.33\", \"min\": \"1\", \"max\": \"4\", \"missing\": \"0\"}}, {\"transformationsData\": {}, \"feature\": \"Customer ID\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"1744.81\", \"stddev\": \"967.81\", \"min\": \"15\", \"max\": \"3394\", \"missing\": \"0\"}}, {\"transformationsData\": {}, \"feature\": \"Store Number\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"102.42\", \"stddev\": \"1.86\", \"min\": \"100\", \"max\": \"105\", \"missing\": \"0\"}}, {\"transformationsData\": {\"feature_label\": \"Customer Segment\"}, \"feature\": \"Customer Segment\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"Consumer\", \"max\": \"Small Business\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"First Name\"}, \"feature\": \"First Name\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"ALXXX\", \"max\": \"WX\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"Last Name\"}, \"feature\": \"Last Name\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"ABXXXXX\", \"max\": \"ZAXXXXXX\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"Address\"}, \"feature\": \"Address\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"1003 WESTVIEW CT\", \"max\": \"9826 NEWLAND CT\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"State\"}, \"feature\": \"State\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"CO\", \"max\": \"CO\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {}, \"feature\": \"Zip\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"80117.81\", \"stddev\": \"102.98\", \"min\": \"80002\", \"max\": \"80403\", \"missing\": \"0\"}}, {\"transformationsData\": {}, \"feature\": \"DriveTime\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"351\", \"mean\": \"13.0\", \"stddev\": \"7.4\", \"min\": \"1.1\", \"max\": \"30.0\", \"missing\": \"0\"}, \"transformation\": \"\"}, {\"transformationsData\": {}, \"feature\": \"Length of Residense\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"10.31\", \"stddev\": \"10.28\", \"min\": \"0\", \"max\": \"50\", \"missing\": \"0\"}}, {\"transformationsData\": {}, \"feature\": \"MOR BANK: UPSCALE MERCHANDISE BUYER\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"0.01\", \"stddev\": \"0.09\", \"min\": \"0\", \"max\": \"1\", \"missing\": \"0\"}}, {\"transformationsData\": {\"feature_label\": \"MOSAIC HOUSEHOLD\"}, \"feature\": \"MOSAIC HOUSEHOLD\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"A01\", \"max\": \"U00\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {\"feature_label\": \"MOSAIC DESCRIPTION\"}, \"feature\": \"MOSAIC DESCRIPTION\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"Autumn Years\", \"max\": \"Young City Solos\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"transformationsData\": {}, \"feature\": \"Customer_Lon\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"351\", \"mean\": \"-104.93\", \"stddev\": \"0.12\", \"min\": \"-105.226518\", \"max\": \"-104.705046\", \"missing\": \"0\"}, \"transformation\": \"\"}, {\"transformationsData\": {}, \"feature\": \"Customer_Lat\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"351\", \"mean\": \"39.7\", \"stddev\": \"0.09\", \"min\": \"39.494126\", \"max\": \"39.998058\", \"missing\": \"0\"}, \"transformation\": \"\"}, {\"transformationsData\": {}, \"feature\": \"Store ID\", \"transformation\": \"\", \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"102.42\", \"stddev\": \"1.86\", \"min\": \"100\", \"max\": \"105\", \"missing\": \"0\"}}, {\"transformationsData\": {}, \"feature\": \"Store_Lon\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"351\", \"mean\": \"-104.93\", \"stddev\": \"0.12\", \"min\": \"-105.077754\", \"max\": \"-104.717928\", \"missing\": \"0\"}, \"transformation\": \"\"}, {\"transformationsData\": {}, \"feature\": \"Store_Lat\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"351\", \"mean\": \"39.7\", \"stddev\": \"0.08\", \"min\": \"39.565799\", \"max\": \"39.856274\", \"missing\": \"0\"}, \"transformation\": \"\"}, {\"transformationsData\": {\"feature_label\": \"Channel\"}, \"feature\": \"Channel\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"351\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"Catalog\", \"max\": \"eCommerce\", \"missing\": \"0\"}, \"transformation\": \"String Indexer\"}, {\"feature\": \"City_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"1.52\", \"stddev\": \"2.2\", \"min\": \"0.0\", \"max\": \"12.0\", \"missing\": \"0\"}}, {\"feature\": \"Product_Category_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"numeric\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"0.63\", \"stddev\": \"0.78\", \"min\": \"0\", \"max\": \"2\", \"missing\": \"0\"}}, {\"feature\": \"Product_Sub-Category_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"4.98\", \"stddev\": \"4.31\", \"min\": \"0.0\", \"max\": \"16.0\", \"missing\": \"0\"}}, {\"feature\": \"Customer Segment_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"numeric\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"1.28\", \"stddev\": \"1.13\", \"min\": \"0\", \"max\": \"3\", \"missing\": \"0\"}}, {\"feature\": \"First Name_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"55.13\", \"stddev\": \"48.16\", \"min\": \"0.0\", \"max\": \"170.0\", \"missing\": \"0\"}}, {\"feature\": \"Last Name_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"79.5\", \"stddev\": \"66.01\", \"min\": \"0.0\", \"max\": \"220.0\", \"missing\": \"0\"}}, {\"feature\": \"Address_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"138.19\", \"stddev\": \"95.52\", \"min\": \"0.0\", \"max\": \"309.0\", \"missing\": \"0\"}}, {\"feature\": \"State_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"numeric\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"0.0\", \"stddev\": \"0.0\", \"min\": \"0\", \"max\": \"0\", \"missing\": \"0\"}}, {\"feature\": \"MOSAIC HOUSEHOLD_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"14.63\", \"stddev\": \"12.17\", \"min\": \"0.0\", \"max\": \"50.0\", \"missing\": \"0\"}}, {\"feature\": \"MOSAIC DESCRIPTION_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"real\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"5.73\", \"stddev\": \"4.47\", \"min\": \"0.0\", \"max\": \"17.0\", \"missing\": \"0\"}}, {\"feature\": \"Channel_transform\", \"transformation\": \"\", \"transformationsData\": {}, \"type\": \"numeric\", \"selected\": \"True\", \"stats\": {\"count\": \"351\", \"mean\": \"0.51\", \"stddev\": \"0.69\", \"min\": \"0\", \"max\": \"2\", \"missing\": \"0\"}}]}))\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "\tdataAutoML=functionClassification(deploymenttestautofe, [\"City\", \"Product_Category\", \"Product_Sub-Category\", \"Count\", \"Customer ID\", \"Store Number\", \"Customer Segment\", \"First Name\", \"Last Name\", \"Address\", \"State\", \"Zip\", \"DriveTime\", \"Length of Residense\", \"MOR BANK: UPSCALE MERCHANDISE BUYER\", \"MOSAIC HOUSEHOLD\", \"MOSAIC DESCRIPTION\", \"Customer_Lon\", \"Customer_Lat\", \"Store ID\", \"Store_Lon\", \"Store_Lat\"], \"Channel\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICT ON TRAINED MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "\n",
    "try:\n",
    "    model=dataAutoML['model']\n",
    "    X_test=dataAutoML['X_test']\n",
    "    y_test=dataAutoML['y_test']\n",
    "    label=dataAutoML['label']\n",
    "    columnNames=dataAutoML['columnNames']\n",
    "    if label in columnNames:\n",
    "        columnNames.remove(label)\n",
    "    predicted=label+\"_predicted\"\n",
    "    y_predicted=model.predict(X_test)\n",
    "    df =pd.DataFrame(X_test , columns=columnNames)\n",
    "    df[label]=y_test\n",
    "    df[predicted]=y_predicted\n",
    "    columnNames.insert(0,predicted)\n",
    "    columnNames.insert(0,label)\n",
    "    Accuracy = round((100 * sklearn.metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)), 1)\n",
    "    F1= round(\n",
    "            (100 * sklearn.metrics.f1_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Precision= round((\n",
    "                100 * sklearn.metrics.precision_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Recall = round((\n",
    "                100 * sklearn.metrics.recall_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    display(\" Accuracy of Prediction on test data    : %s\"%Accuracy)\n",
    "    display(\" F1 score of Prediction on test data    : %s\"%F1)\n",
    "    display(\" Precision of Prediction on test data   : %s\"%Precision)\n",
    "    display(\" Recall of Prediction on test data      : %s\"%Recall)\n",
    "    display(df.head())\n",
    "except Exception as ex:\n",
    "    logging.error(ex)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
